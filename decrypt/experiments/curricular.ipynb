{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setting up for curricular experiment\n",
    "\n",
    "This assumes you have already followed the instructions in `baselines/baseline_t5`, which will set up the baseline clue files for model input\n",
    "\n",
    "### Datasets\n",
    "1. Download and unzip the xd cw crossword set from http://xd.saul.pw/xd-clues.zip.\n",
    "    - Save it as './data/original/xd/clues.tsv'\n",
    "2. Preprocess the dataset using this notebook\n",
    "3. The dataset will be saved to k_acw_export_dir (as a single train.json file)\n",
    "4. We will also produce the anagram dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No gsheets writer is configured\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "path = str(Path(Path.cwd()).parent.absolute())\n",
    "# sys.path.insert(0, path)\n",
    "sys.path.append(path) \n",
    "from decrypt.scrape_parse.acw_load import get_clean_xd_clues\n",
    "from decrypt import config\n",
    "from decrypt.common.util_data import clue_list_tuple_to_train_split_json\n",
    "from decrypt.common import validation_tools as vt\n",
    "\n",
    "# k_xd_orig_tsv = config.DataDirs.OriginalData.k_xd_cw        # ./data/original/xd/clues.tsv\n",
    "k_xd_orig_tsv = '../data/xd/clues.tsv'\n",
    "k_acw_export_dir = config.DataDirs.DataExport.xd_cw_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loading xd (ACW) set from ../data/xd/clues.tsv\n",
      "6065905it [00:20, 292143.21it/s]\n",
      "INFO:root:Counter({'removed_trailing_period': 633635, 'fillin': 371248, 'question word': 163541, 'removed_likely_abbrev': 161296, 'ref': 42025, 'empty': 2678})\n",
      "INFO:root:Filtered to 5325117 clues\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'removed_trailing_period': 633635, 'fillin': 371248, 'question word': 163541, 'removed_likely_abbrev': 161296, 'ref': 42025, 'empty': 2678})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5325117/5325117 [00:02<00:00, 2498009.16it/s]\n",
      "100%|██████████| 239577/239577 [00:23<00:00, 10009.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 3090254 exact dupes\n",
      "2234863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Counter({1: 2234863})\n",
      "100%|██████████| 2234863/2234863 [00:03<00:00, 645168.26it/s]\n",
      "INFO:decrypt.common.util_data:Source target mapping:\n",
      "\tLitigator's group (3) => aba\n",
      "\n",
      "INFO:decrypt.common.util_data:Finished writing all files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 0, 'input': \"Litigator's group (3)\", 'target': 'aba'}\n",
      "{'idx': 1, 'input': 'Arab garment (3)', 'target': 'aba'}\n",
      "{'idx': 2, 'input': 'Arabian garment (3)', 'target': 'aba'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defaults to strip periods, remove questions, remove abbrevs, remove fillin\n",
    "stc_map, all_clues = get_clean_xd_clues(k_xd_orig_tsv,\n",
    "                                        remove_if_not_in_dict=False,\n",
    "                                        do_filter_dupes=True)\n",
    "clue_list_tuple_to_train_split_json((all_clues,),\n",
    "                                    comment='ACW set; xd cw set, all',\n",
    "                                    export_dir=k_acw_export_dir,\n",
    "                                    overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Overwriting database at /home/abdelrahman.sadallah/mbzuai/decrypting-crosswords/decrypt/data/generated/anag_db\n",
      "INFO:root:Adding to db /home/abdelrahman.sadallah/mbzuai/decrypting-crosswords/decrypt/data/generated/anag_db with updateflag overwrite\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118619it [01:15, 1563.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 118609})\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# produce anagram datasets\n",
    "# roughly 3 minutes to complete\n",
    "from decrypt.common import anagrammer\n",
    "anagrammer.gen_db_with_both_inputs(update_flag=\"overwrite\")\n",
    "\n",
    "from decrypt.common.util_data import (\n",
    "    get_anags,\n",
    "    write_json_tuple\n",
    ")\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_anag_sets_json():\n",
    "    all_anags = get_anags(max_num_words=-1)\n",
    "    json_list = []\n",
    "    for idx, a_list in enumerate(all_anags):\n",
    "        json_list.append(dict(idx=idx,\n",
    "                              anag_list=a_list))\n",
    "    print(json_list[0])\n",
    "\n",
    "    # normally would be (idx, input, tgt)\n",
    "    output_tuple = [json_list,]\n",
    "\n",
    "    os.makedirs(config.DataDirs.DataExport.anag_dir)\n",
    "    write_json_tuple(output_tuple,\n",
    "                     comment=\"List of all anagram groupings\",\n",
    "                     export_dir=config.DataDirs.DataExport.anag_dir,\n",
    "                     overwrite=False)\n",
    "\n",
    "def make_anag_indic_list_json():\n",
    "    # make the indicator list\n",
    "    with open(config.DataDirs.OriginalData.k_deits_anagram_list, 'r') as f:\n",
    "        all_anag_indicators = f.readlines()\n",
    "        print(len(all_anag_indicators))\n",
    "\n",
    "    final_indic_list = []\n",
    "    for a in all_anag_indicators:\n",
    "        final_indic_list.append(a.replace('_', \" \").strip())\n",
    "    with open(config.DataDirs.DataExport.anag_indics, 'w') as f:\n",
    "        json.dump(final_indic_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing (non-singleton) Anagrammer from /home/abdelrahman.sadallah/mbzuai/decrypting-crosswords/decrypt/data/generated/anag_db\n",
      "INFO:root:DONE: Initialized Anagrammer from /home/abdelrahman.sadallah/mbzuai/decrypting-crosswords/decrypt/data/generated/anag_db\n",
      "100%|██████████| 110341/110341 [00:18<00:00, 5843.17it/s]\n",
      "INFO:root:Total anagramable: 6543\n",
      "INFO:decrypt.common.util_data:Finished writing all files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6543\n",
      "6543\n",
      "14811\n",
      "['ah', 'ha']\n",
      "{'idx': 0, 'anag_list': ['ah', 'ha']}\n",
      "{'anag_list': ['ah', 'ha'], 'idx': 0}\n",
      "{'anag_list': ['al', 'la'], 'idx': 1}\n",
      "{'anag_list': ['am', 'ma'], 'idx': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "make_anag_sets_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160\n"
     ]
    }
   ],
   "source": [
    "make_anag_indic_list_json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Curricular training\n",
    "1. At this point you should have a files at\n",
    " - `./data/clue_json/curricular/ACW/train.json`\n",
    " - `./data/clue_json/curricular/anagram/[train.json, anag_indics.json]`\n",
    "\n",
    "2. Running curricular training is the same as running main t5 vanilla train, except that we pass an extra multitask flag, which specifies the curriculum to use. See `seq2seq/multitask_config`. You should pass one of the names from  `multi_config` dict in that file\n",
    "\n",
    "For example, to train the naive split with the top performing curricular approach (i.e. the result in table 3 that is ACW + ACW-descramble)\n",
    "```python\n",
    "python train_clues.py --default_train=base --name=naive_top_curricular --project=curricular --wandb_dir='./wandb' --data_dir='../data/clue_json/guardian/naive_random' --multitask=ACW__ACW_descramble\n",
    "```\n",
    "\n",
    "Note that the modifications on the dataset are done at the\n",
    "\n",
    "3. To produce Table 3 of the results\n",
    "    -  we don't need to do a model_eval run since the outputted predictions have 5 generations\n",
    "       (which is all we report for that table (for faster experimental iteration).\n",
    "    - we need to run `load_and_run_t5` on all outputs (column 1) and on the anagram subset (column 2)\n",
    "      See below for how we do this.\n",
    "\n",
    "4. For our top result in Table 2 (main resuls) we\n",
    "    1. scale up the curricular period (to 4 total epochs)\n",
    "```python\n",
    "python train_clues.py --default_train=base --name=naive_top_curricular --project=curricular --wandb_dir='./wandb' --data_dir='../data/clue_json/guardian/naive_random' --multitask=final_top_result_scaled_up\n",
    "```\n",
    "    2. eval with full 100 generations, as before:\n",
    "e.g., if epoch 10 is best (you'll need to set the run_name)\n",
    "This runs the eval set (change the run_name)\n",
    "```python\n",
    "python train_clues.py --default_val=base --name=curricular_naive_top --project=curricular --data_dir='../data/clue_json/guardian/naive_random' --ckpt_path='./wandb/run_name/files/epoch_10.pth.tar\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from decrypt.common.label_anagrams import make_label_set\n",
    "\n",
    "labels = make_label_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# note that this should be run directly on the top model output from curricular training\n",
    "# otherwise (eg. if 100 beams were used), the top 5 output\n",
    "# sequences would be expected to change\n",
    "# remember not to append .json\n",
    "\n",
    "# eval on the full output (5 beams / 5 sequences)\n",
    "# this is column 1 of table 3\n",
    "vt.load_and_run_t5('outputs/model_output.preds',\n",
    "                   # pre_truncate=5,        # should not be needed since we have only 5 outputs\n",
    "                   do_length_filter=True)\n",
    "\n",
    "# run on the anagram subset\n",
    "# this is column 2 of table 3\n",
    "vt.load_and_run_t5('outputs/model_output.preds',\n",
    "                   filter_fcn=vt.make_set_filter(labels, 'anag_direct'),\n",
    "                   # pre_truncate=5,\n",
    "                   do_length_filter=True)\n",
    "\n",
    "# we are looking at agg_top_match (which is after filter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
