{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /home/abdelrahman.sadallah/local/cuda-11.7/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/abdelrahman.sadallah/.conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman.sadallah/.conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: /home/abdelrahman.sadallah/.conda/envs/nlp did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d146053f546f49928853b9eb129ea390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    return_dict=True,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "     \n",
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "# train_dataset = load_dataset('json', data_files=\"data/naive_random.json\", field=\"train\",split=\"train\")\n",
    "val_dataset = load_dataset('json', data_files=\"../data/naive_random.json\", field=\"val\",split=\"train\")\n",
    "# test_dataset = load_dataset('json', data_files=\"data/naive_random.json\", field=\"test\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique types is: 1\n",
      " total number of examples: 28476,    number of unique answers: 20302\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "unique_answers = np.unique(val_dataset['soln'])\n",
    "\n",
    "unique_answers = pd.DataFrame(unique_answers)\n",
    "\n",
    "\n",
    "unique_type = np.unique(val_dataset['type'])\n",
    "print(f'Total number of unique types is: {len(unique_type)}')\n",
    "\n",
    "print(f' total number of examples: {len(val_dataset)},    number of unique answers: {len(unique_answers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_length(example):\n",
    "\n",
    "    example[\"clue\"] = f'{example[\"clue\"]} ({example[\"orig_lengths\"]})'\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_metric = load(\"accuracy\")\n",
    "\n",
    "val_dataset = val_dataset.map(concat_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Below is a clue for a decrypting crossword. Your task is to solve this clue. The number of charachters in the answer should be same as the number in the parenthesis. Just output the answer only. Do not output any explanitions, just the words in the answer.\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "I will give you a cryptic crossword which is a crossword puzzle in which each clue is a word puzzle. Your task is to solve this clue. The number of charachters in the answer should be same as the numbers in the parenthesis in the clue.\n",
    "\n",
    "### Input:\n",
    "Desk register taken no further than Ozzie? (7)\n",
    "\n",
    "### Output:\n",
    "rolltop\n",
    "\n",
    "### Input:\n",
    "Henry has books stolen (3)\n",
    "\n",
    "### Output:\n",
    "hot\n",
    "\n",
    "### Input:\n",
    "What's missing in a fight is obscure (5,3)\n",
    "\n",
    "### Output:\n",
    "black out\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_training_prompt(\n",
    "    clue: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    return f\"\"\"### Instruction: {system_prompt}\n",
    "\n",
    "### Input:\n",
    "{clue.strip()}\n",
    "\n",
    "\"\"\".strip()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"### Instruction: Below is a clue for a decrypting crossword. Your task is to solve this clue. The number of charachters in the answer should be same as the number in the parenthesis. Just output the answer only. Do not output any explanitions, just the words in the answer.\\n \\n### Input:\\nDesk register taken no further than Ozzie? (7)\\n\\n### Output:\\nrolltop\\n\\n### Input:\\nHenry has books stolen (3)\\n\\n### Output:\\nhot\\n\\n### Input:\\nWhat's missing in a fight is obscure (5,3)\\n\\n### Output:\\nblack out\\n\\n### Input:\\nDesk register taken no further than Ozzie? (7)\",\n",
       " 'soln_with_spaces': 'rolltop',\n",
       " 'clue': 'Desk register taken no further than Ozzie? (7)'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction: I will give you a cryptic crossword which is a crossword puzzle in which each clue is a word puzzle. Your task is to solve this clue. The number of charachters in the answer should be same as the numbers in the parenthesis in the clue.\n",
      "\n",
      "### Input:\n",
      "Desk register taken no further than Ozzie? (7)\n",
      "\n",
      "### Output:\n",
      "rolltop\n",
      "\n",
      "### Input:\n",
      "Henry has books stolen (3)\n",
      "\n",
      "### Output:\n",
      "hot\n",
      "\n",
      "### Input:\n",
      "What's missing in a fight is obscure (5,3)\n",
      "\n",
      "### Output:\n",
      "black out\n",
      "\n",
      "### Input:\n",
      "Eccentric uncle has a right to form basic kind of family (7)\n"
     ]
    }
   ],
   "source": [
    "prompt = generate_training_prompt(val_dataset[10]['clue'])\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_answer(res):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prompt(ex):\n",
    "    ex['prompt'] =  generate_training_prompt(ex[\"clue\"])\n",
    "\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc434ebdc8748559fe5eb7e09e68891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_dataset = val_dataset.map(map_prompt)\n",
    "\n",
    "val_dataset = val_dataset.select_columns(['prompt', 'soln_with_spaces', 'clue' ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"### Instruction: I will give you a cryptic crossword which is a crossword puzzle in which each clue is a word puzzle. Your task is to solve this clue. The number of charachters in the answer should be same as the numbers in the parenthesis in the clue.\\n\\n### Input:\\nDesk register taken no further than Ozzie? (7)\\n\\n### Output:\\nrolltop\\n\\n### Input:\\nHenry has books stolen (3)\\n\\n### Output:\\nhot\\n\\n### Input:\\nWhat's missing in a fight is obscure (5,3)\\n\\n### Output:\\nblack out\\n\\n### Input:\\nWhat's missing in a fight is obscure (5,3)\",\n",
       " 'soln_with_spaces': 'black out',\n",
       " 'clue': \"What's missing in a fight is obscure (5,3)\"}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompts):\n",
    "    \n",
    "   \n",
    "    encoding = tokenizer(prompts, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **encoding,\n",
    "            max_new_tokens=64,\n",
    "            temperature=0.00001,\n",
    "            generation_config=generation_config,\n",
    "        )  \n",
    "\n",
    "    answer_tokens = outputs[:, encoding.input_ids.shape[1] :]\n",
    "    return answer_tokens\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVAL LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "from tqdm import tqdm\n",
    "\n",
    "# TOTAL = 100\n",
    "TOTAL = len(val_dataset)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset.select(range(TOTAL)),batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_dataset.select(range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 890/890 [3:12:39<00:00, 12.99s/it]  \n"
     ]
    }
   ],
   "source": [
    "            # Define PAD Token = BOS Token\n",
    "            tokenizer.pad_token = tokenizer.bos_token\n",
    "            model.config.pad_token_id = model.config.bos_token_id\n",
    "\n",
    "\n",
    "            predictions = []\n",
    "            labels = []\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            for batch in tqdm(val_dataloader):\n",
    "\n",
    "                prompts = batch['prompt']\n",
    "                labels.extend (batch['soln_with_spaces'])\n",
    "                ans = []\n",
    "\n",
    "                outputs = inference(prompts=prompts)\n",
    "                output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "                for i in output_text:\n",
    "\n",
    "                    lines = i.split('\\n')\n",
    "                    for i,l in enumerate(lines):\n",
    "                        if l=='### Output:':\n",
    "                            predictions.append( lines[i+1].lower())\n",
    "                            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28476\n",
      "ACCURACY:  0.02423093131057733\n",
      "Length error:  0.8132462424497823\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import emoji\n",
    "assert (len(predictions) == len(labels))\n",
    "\n",
    "\n",
    "correct = 0\n",
    "length_error =0\n",
    "\n",
    "\n",
    "with open('pred_output.txt', 'w') as f:\n",
    "    for pred,label in zip(predictions,labels):\n",
    "\n",
    "        correctly_predicted = False\n",
    "        if pred == label:\n",
    "            correct +=1\n",
    "            correctly_predicted = True\n",
    "\n",
    "        if len(pred) == len(label):\n",
    "            length_error +=1\n",
    "\n",
    "        if correctly_predicted:\n",
    "            f.write(emoji.emojize(f'{pred} | {label}  :check_mark_button: \\n'))\n",
    "        else:\n",
    "            f.write(emoji.emojize(f'{pred} | {label}  :cross_mark: \\n'))\n",
    "\n",
    "\n",
    "print(TOTAL)\n",
    "print(f'ACCURACY:  { float (correct / TOTAL)}')\n",
    "print(f'Length error:  { float (1 - (length_error / TOTAL) )}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        \n",
    "    # id = i.find('### Output:')\n",
    "    # print(i[id:])\n",
    "\n",
    "    # nl = i.find\n",
    "    # # print(i)\n",
    "\n",
    "#     print(ans)\n",
    "\n",
    "# print(labels)\n",
    "# print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
