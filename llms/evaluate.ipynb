{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /home/abdelrahman.sadallah/local/cuda-11.7/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/abdelrahman.sadallah/.conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman.sadallah/.conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: /home/abdelrahman.sadallah/.conda/envs/nlp did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c375de7f2cd4f14bad2030dfadfb67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    return_dict=True,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "     \n",
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "# train_dataset = load_dataset('json', data_files=\"data/naive_random.json\", field=\"train\",split=\"train\")\n",
    "val_dataset = load_dataset('json', data_files=\"../data/naive_random.json\", field=\"val\",split=\"train\")\n",
    "# test_dataset = load_dataset('json', data_files=\"data/naive_random.json\", field=\"test\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique types is: 1\n",
      " total number of examples: 28476,    number of unique answers: 20302\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "unique_answers = np.unique(val_dataset['soln'])\n",
    "\n",
    "unique_answers = pd.DataFrame(unique_answers)\n",
    "\n",
    "\n",
    "unique_type = np.unique(val_dataset['type'])\n",
    "print(f'Total number of unique types is: {len(unique_type)}')\n",
    "\n",
    "print(f' total number of examples: {len(val_dataset)},    number of unique answers: {len(unique_answers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_length(example):\n",
    "\n",
    "    example[\"clue\"] = f'{example[\"clue\"]} ({example[\"orig_lengths\"]})'\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_metric = load(\"accuracy\")\n",
    "\n",
    "val_dataset = val_dataset.map(concat_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "Below is a clue for a decrypting crossword. Your task is to solve this clue. The number of charachters in the answer should be same as the number in the parenthesis. Just output the answer only. Do not output any explanitions, just the words in the answer. \n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_training_prompt(\n",
    "    clue: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    return f\"\"\"### Instruction: {system_prompt}\n",
    "\n",
    "### Input:\n",
    "{clue.strip()}\n",
    "\n",
    "\"\"\".strip()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'soln': 'rolltop',\n",
       " 'type': 'cryptic',\n",
       " 'idx': 67935,\n",
       " 'pos': [0, 0],\n",
       " 'dataset': '',\n",
       " 'unique_clue_id': '',\n",
       " 'lengths': [7],\n",
       " 'number': 0,\n",
       " 'lengths_punctuation': [],\n",
       " 'id': '',\n",
       " 'creator': 'Enigmatist',\n",
       " 'clue': 'Desk register taken no further than Ozzie? (7)',\n",
       " 'orig_lengths': '7',\n",
       " 'soln_with_spaces': 'rolltop',\n",
       " 'across_or_down': ''}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction: Below is a clue for a decrypting crossword. Your task is to solve this clue. The number of charachters in the answer should be same as the number in the parenthesis. Just output the answer only. Do not output any explanitions, just the words in the answer.\n",
      "\n",
      "### Input:\n",
      "Eccentric uncle has a right to form basic kind of family (7)\n"
     ]
    }
   ],
   "source": [
    "prompt = generate_training_prompt(val_dataset[10]['clue'])\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_answer(res):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prompt(ex):\n",
    "    ex['prompt'] =  generate_training_prompt(ex[\"clue\"])\n",
    "\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = val_dataset.map(map_prompt)\n",
    "\n",
    "val_dataset = val_dataset.select_columns(['prompt', 'soln_with_spaces', 'clue' ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '### Instruction: Below is a clue for a decrypting crossword. Your task is to solve this clue. The number of charachters in the answer should be same as the number in the parenthesis. Just output the answer only. Do not output any explanitions, just the words in the answer.\\n\\n### Input:\\nDesk register taken no further than Ozzie? (7)',\n",
       " 'soln_with_spaces': 'rolltop',\n",
       " 'clue': 'Desk register taken no further than Ozzie? (7)'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompts):\n",
    "    \n",
    "   \n",
    "    encoding = tokenizer(prompts, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **encoding,\n",
    "            max_new_tokens=64,\n",
    "            temperature=0.00001,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "\n",
    "    answer_tokens = outputs[:, encoding.input_ids.shape[1] :]\n",
    "    return answer_tokens\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVAL LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset.select(range(100)),batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_dataset.select(range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:20<00:00, 10.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define PAD Token = BOS Token\n",
    "tokenizer.pad_token = tokenizer.bos_token\n",
    "model.config.pad_token_id = model.config.bos_token_id\n",
    "\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for batch in tqdm(val_dataloader):\n",
    "\n",
    "    prompts = batch['prompt']\n",
    "    labels.extend (batch['soln_with_spaces'])\n",
    "    ans = []\n",
    "\n",
    "    outputs = inference(prompts=prompts)\n",
    "    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    for i in output_text:\n",
    "\n",
    "        lines = i.split('\\n')\n",
    "        for i,l in enumerate(lines):\n",
    "            if l=='### Output:':\n",
    "                predictions.append( lines[i+1].lower())\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.0\n",
      "Length error:  -5.0\n"
     ]
    }
   ],
   "source": [
    "assert (len(predictions) == len(labels))\n",
    "\n",
    "total = len(val_dataloader)\n",
    "correct = 0\n",
    "length_error =0\n",
    "\n",
    "with open('pred_output.txt', 'w') as f:\n",
    "    for pred,label in zip(predictions,labels):\n",
    "        if pred == label:\n",
    "            correct +=1\n",
    "\n",
    "        if len(pred) == len(label):\n",
    "            length_error +=1\n",
    "\n",
    "        f.write(f'{pred} | {label} \\n')\n",
    "\n",
    "\n",
    "print(f'ACCURACY:  { float (correct / total)}')\n",
    "print(f'Length error:  { float (1 - length_error / total)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozzie\n",
      "morgan\n",
      "farm\n",
      "eucharist\n",
      "riotous\n",
      "['rolltop', 'aesop', 'myriad', 'before', 'troublesome']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "        \n",
    "    # id = i.find('### Output:')\n",
    "    # print(i[id:])\n",
    "\n",
    "    # nl = i.find\n",
    "    # # print(i)\n",
    "\n",
    "#     print(ans)\n",
    "\n",
    "# print(labels)\n",
    "# print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
