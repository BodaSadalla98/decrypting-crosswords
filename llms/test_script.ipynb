{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer\n",
    "import datasets\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader \n",
    "from tqdm import tqdm\n",
    "import emoji\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "# MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "def add_args(parser: argparse.ArgumentParser):\n",
    "\n",
    "    parser.add_argument('--model_name',\n",
    "                            type=str,\n",
    "                            default='meta-llama/Llama-2-7b-hf')\n",
    "\n",
    "    parser.add_argument('--save_file',\n",
    "                                type=str,\n",
    "                                default='pred_output.txt')\n",
    "    \n",
    "    parser.add_argument('--batch_size',\n",
    "                            type=int,\n",
    "                            default=32)\n",
    "    \n",
    "    parser.add_argument('--prompt',\n",
    "                            type=str,\n",
    "                            default=\"\"\"\n",
    "Below is a clue for a decrypting crossword. Your task is to solve this clue. The number of charachters in the answer should be same as the number in the parenthesis. Just output the answer only. Do not output any explanitions, just the words in the answer.\n",
    " \n",
    "### Input:\n",
    "Desk register taken no further than Ozzie? (7)\n",
    "\n",
    "### Output:\n",
    "rolltop\n",
    "\n",
    "### Input:\n",
    "Henry has books stolen (3)\n",
    "\n",
    "### Output:\n",
    "hot\n",
    "\"\"\")\n",
    "    \n",
    "    parser.add_argument('--num_examples',\n",
    "                            type=int,\n",
    "                            default=0)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def concat_length(example):\n",
    "\n",
    "    example[\"clue\"] = f'{example[\"clue\"]} ({example[\"orig_lengths\"]})'\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "Below is a clue for a decrypting crossword. Your task is to solve this clue. The number of charachters in the answer should be same as the number in the parenthesis. Just output the answer only. Do not output any explanitions, just the words in the answer.\n",
    " \n",
    "### Input:\n",
    "Desk register taken no further than Ozzie? (7)\n",
    "\n",
    "### Output:\n",
    "rolltop\n",
    "\n",
    "### Input:\n",
    "Henry has books stolen (3)\n",
    "\n",
    "### Output:\n",
    "hot\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_training_prompt(\n",
    "    clue: str, prompt: str = DEFAULT_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    return f\"\"\"### Instruction: {prompt}\n",
    "\n",
    "### Input:\n",
    "{clue.strip()}\n",
    "\n",
    "\"\"\".strip()\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def map_prompt(ex, prompt):\n",
    "    ex['prompt'] =  generate_training_prompt(ex[\"clue\"])\n",
    "\n",
    "    return ex\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def inference(prompts, tokenizer, generation_config, model):\n",
    "    \n",
    "   \n",
    "    encoding = tokenizer(prompts, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **encoding,\n",
    "            max_new_tokens=64,\n",
    "            temperature=0.00001,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            generation_config=generation_config,\n",
    "        )  \n",
    "\n",
    "    answer_tokens = outputs[:, encoding.input_ids.shape[1] :]\n",
    "    return answer_tokens\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "val_dataset = load_dataset('json', data_files=\"../data/naive_random.json\", field=\"val\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "idx= np.random.randint(0,100,10)\n",
    "\n",
    "x= val_dataset.select(idx)['clue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"They're shaken, swapping tips on communism for city\",\n",
       " 'Photo developed thanks to delicate matter',\n",
       " \"What's missing in a fight is obscure\",\n",
       " 'Photo developed thanks to delicate matter',\n",
       " \"Derive support from article in house that's new\",\n",
       " 'Targets given by teachers for work',\n",
       " 'How one comes to confess',\n",
       " 'Prior to support leader in Eucharist',\n",
       " 'Ken exits wounded, holding up TV award, though showing good balance',\n",
       " \"Aphrodisiac - it's in the heart, rising\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
