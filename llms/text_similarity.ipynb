{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/included/chatgpt_eval_results_32627_3shots_learning.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "similarities_dict = []\n",
    "base_dir = 'outputs/included'\n",
    "\n",
    "dir =directory = os.fsencode(base_dir)\n",
    "\n",
    "\n",
    "files = os.listdir(directory)[6:]\n",
    "for file in tqdm(files):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "\n",
    "    if filename.endswith(\".txt\"):\n",
    "        sim = 0.0\n",
    "        cnt = 0\n",
    "\n",
    "        save_name = filename\n",
    "        filename = os.path.join(base_dir, filename)\n",
    "        print(filename)\n",
    "        lines = []\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "\n",
    "            lines = list(lines[7:])\n",
    "            # for i,line in enumerate(tqdm(lines)):\n",
    "            for i,line in tqdm(enumerate(lines)):\n",
    "                if   ('-' * 10 ) in  line:\n",
    "\n",
    "                    # ' '.join(output_file[i+3].split('|')[1].split(' ')[1:-3])\n",
    "                    line_segments = lines[i-1].split('|')\n",
    "\n",
    "                    if len(line_segments)< 2:\n",
    "                        print(line)\n",
    "                    label = ' '.join(line_segments[1].split(' ')[1:-3]).strip()\n",
    "                    prediction = line_segments[0].strip()\n",
    "\n",
    "                    ### Only consider the wrong examples\n",
    "                    if label == prediction:\n",
    "                        continue\n",
    "\n",
    "                    embedding_1= model.encode(label, convert_to_tensor=True)\n",
    "                    embedding_2 = model.encode(prediction, convert_to_tensor=True)\n",
    "                    sim += util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "                    cnt += 1\n",
    "\n",
    "        # save_key = filename.split('.txt')[0] + '_similarity.txt'\n",
    "        \n",
    "        # similarities_dict[save_key] = sim/cnt\n",
    "        similarities_dict.append({'filename': save_name, 'similarity' : sim.item()/cnt})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #Compute embedding for both lists\n",
    "# embedding_1= model.encode(sentences[0], convert_to_tensor=True)\n",
    "# embedding_2 = model.encode(sentences[1], convert_to_tensor=True)\n",
    "\n",
    "# sim = util.pytorch_cos_sim(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results_path = base_dir  + 'similarity_results.json'\n",
    "\n",
    "with open(save_results_path, 'w')as f:\n",
    "    json.dump(similarities_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': 'chatgpt_eval_results_32627_3shots_learning.txt',\n",
       "  'similarity': 0.33077642226581655},\n",
       " {'filename': 'mistral_normal_3_few_shot.txt',\n",
       "  'similarity': 0.2875641987035964},\n",
       " {'filename': 'mistral_cryptonite_1.5_cryptonite_test.txt',\n",
       "  'similarity': 0.3811923508889314},\n",
       " {'filename': 'mistral_indicator_0_few_shot.txt',\n",
       "  'similarity': 0.2593704885660021},\n",
       " {'filename': 'mistral_disjoint_2_new_2k_output_test_disjoint.txt',\n",
       "  'similarity': 0.26024830375446123},\n",
       " {'filename': 'mistral_disjoint_2k_test_output_disjoint.txt',\n",
       "  'similarity': 0.26105373810024185},\n",
       " {'filename': 'llama_normal_3_few_shot.txt', 'similarity': 0.2812141244556246},\n",
       " {'filename': 'llama_naive_1.5k_output_test_naive.txt',\n",
       "  'similarity': 0.343307856913565},\n",
       " {'filename': 'chatgpt_eval_results_32619.txt',\n",
       "  'similarity': 0.3055509745504507},\n",
       " {'filename': 'llama_disjoint_1.5k_output_test_disjoint.txt',\n",
       "  'similarity': 0.2592230742492171},\n",
       " {'filename': 'mistral_indicator_3_few_shot.txt',\n",
       "  'similarity': 0.28440751092592104},\n",
       " {'filename': 'mistral_normal_10_few_shot.txt',\n",
       "  'similarity': 0.2875818449441137},\n",
       " {'filename': 'mistral_word_init_disjoint_unique_3k.txt',\n",
       "  'similarity': 0.26313528310976064},\n",
       " {'filename': 'mistral_disjoint_half_targets_2_new_2k_output_test_disjoint_half_targets.txt',\n",
       "  'similarity': 0.26776790342087076},\n",
       " {'filename': 'mistral_naive_random_unique_3k.txt',\n",
       "  'similarity': 0.30847387758935974},\n",
       " {'filename': 'mistral_disjoint_1k_cryptonite_filtered_quick_testset.txt',\n",
       "  'similarity': 0.3009685043000827},\n",
       " {'filename': 'llama_indicator_0_few_shot.txt',\n",
       "  'similarity': 0.2580926400048296},\n",
       " {'filename': 'llama_disjoint_2_new_1.5k_output_test_disjoint.txt',\n",
       "  'similarity': 0.2597940873071477},\n",
       " {'filename': 'llama_normal_10_few_shot.txt',\n",
       "  'similarity': 0.28432205784866366},\n",
       " {'filename': 'llama_indicator_10_few_shot.txt',\n",
       "  'similarity': 0.2825425424814291},\n",
       " {'filename': 'llama_indicator_3_few_shot.txt',\n",
       "  'similarity': 0.27935332925051803}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs/includedsimilarity_results.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
