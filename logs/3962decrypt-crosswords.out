starting.......................
[10.11 10:21:49] [train_clues.py:132 - <module>()]	 train_clues.py --default_train=base --name=naive_random_Cirrucular --project=baseline --wandb_dir=../../wandb --data_dir=../data/clue_json/guardian/naive_random --num_epochs=25 --multitask=final_top_result_scaled_up --batch_size=64
[10.11 10:21:49] [util.py:168 - set_seed()]	 Setting seed
[10.11 10:21:50] [util_checkpoint.py:65 - __init__()]	 Saver will track (metric, maximize?)
 [('dev/num_match_top_sampled', True), ('multisave', True), ('multi/acw/num_match_in_sample', True), ('epoch', True)]
[10.11 10:21:50] [util.py:86 - get_available_devices()]	 Device: cuda:0	 GPU IDs: [0]	 machine: ws-l6-020

[10.11 10:23:28] [train_abc.py:782 - setup_dataloaders_multi()]	 Setting up for multitask
[10.11 10:23:28] [util_dataloader_batch.py:56 - __init__()]	 Loading cluedatasetbatched of type train
[10.11 10:23:29] [util_dataloader_batch.py:72 - __init__()]	 For dataset, found readme: 
[10.11 10:23:29] [util_dataloader_batch.py:73 - __init__()]	 ['Guardian data. Split: naive_random\n', 'Total: 142380\n', 'splits: [85428, 28476, 28476]\n', '\n', "{'idx': -1,\n", " 'input': 'Suffering to grasp edge of plant (8)',\n", " 'target': 'agrimony'}\n", "{'idx': -1,\n", " 'input': 'Honour Ben and Noel with new order (7)',\n", " 'target': 'ennoble'}\n", "{'idx': -1, 'input': 'Bit the royal we love? Cheers! (4)', 'target': 'iota'}\n", '\n', '\n']
[10.11 10:23:30] [util_dataloader_batch.py:197 - _get_dataloader_batched()]	 Dataset train loaded with size: 85428
[10.11 10:23:51] [util_dataloader_batch.py:34 - __post_init_check()]	 Dataloader:
	Try to convert Senegal? I've failed (10) => evangelise
[10.11 10:23:51] [util_dataloader_batch.py:174 - _get_dataloader_from_dataset()]	 Dataloader loaded from dataset
[10.11 10:23:51] [util_dataloader_batch.py:56 - __init__()]	 Loading cluedatasetbatched of type val
[10.11 10:23:51] [util_dataloader_batch.py:197 - _get_dataloader_batched()]	 Dataset val loaded with size: 28476
[10.11 10:23:52] [util_dataloader_batch.py:34 - __post_init_check()]	 Dataloader:
	Desk register taken no further than Ozzie? (7) => rolltop
[10.11 10:23:52] [util_dataloader_batch.py:174 - _get_dataloader_from_dataset()]	 Dataloader loaded from dataset
[10.11 10:23:52] [util_multiloader.py:110 - _prepare_dataloaders()]	 For task acw, using cfg-provided collate function
[10.11 10:23:52] [util_dataloader_batch.py:56 - __init__()]	 Loading cluedatasetbatched of type train
[10.11 10:23:52] [util_dataloader_batch.py:72 - __init__()]	 For dataset, found readme: 
[10.11 10:23:52] [util_dataloader_batch.py:73 - __init__()]	 ['ACW set; xd cw set, all\n', 'Total: 2234863\n', 'splits: [2234863]\n', '\n', '{\'idx\': 0, \'input\': "Litigator\'s group (3)", \'target\': \'aba\'}\n', "{'idx': 1, 'input': 'Arab garment (3)', 'target': 'aba'}\n", "{'idx': 2, 'input': 'Arabian garment (3)', 'target': 'aba'}\n", '\n', '\n']
[10.11 10:24:49] [util_dataloader_batch.py:34 - __post_init_check()]	 Dataloader:
	phrase: Getting through a busy toll plaza, e.g (6) => hassle
[10.11 10:24:55] [util_dataloader_batch.py:174 - _get_dataloader_from_dataset()]	 Dataloader loaded from dataset
[10.11 10:25:12] [util_dataloader_batch.py:34 - __post_init_check()]	 Dataloader:
	phrase: Darks or whites (4) => load
[10.11 10:25:16] [util_dataloader_batch.py:174 - _get_dataloader_from_dataset()]	 Dataloader loaded from dataset
[10.11 10:25:16] [util_multiloader.py:110 - _prepare_dataloaders()]	 For task acw_descramble, using cfg-provided collate function
[10.11 10:25:16] [util_dataloader_batch.py:56 - __init__()]	 Loading cluedatasetbatched of type train
[10.11 10:25:16] [util_dataloader_batch.py:72 - __init__()]	 For dataset, found readme: 
[10.11 10:25:16] [util_dataloader_batch.py:73 - __init__()]	 ['ACW set; xd cw set, all\n', 'Total: 2234863\n', 'splits: [2234863]\n', '\n', '{\'idx\': 0, \'input\': "Litigator\'s group (3)", \'target\': \'aba\'}\n', "{'idx': 1, 'input': 'Arab garment (3)', 'target': 'aba'}\n", "{'idx': 2, 'input': 'Arabian garment (3)', 'target': 'aba'}\n", '\n', '\n']
[10.11 10:26:31] [util_dataloader_batch.py:34 - __post_init_check()]	 Dataloader:
	descramble: essta charm or poise (5) => asset
[10.11 10:26:35] [util_dataloader_batch.py:174 - _get_dataloader_from_dataset()]	 Dataloader loaded from dataset
[10.11 10:26:45] [util_dataloader_batch.py:34 - __post_init_check()]	 Dataloader:
	descramble: aodl darks or whites (4) => load
[10.11 10:26:50] [util_dataloader_batch.py:174 - _get_dataloader_from_dataset()]	 Dataloader loaded from dataset
[10.11 10:26:50] [util_multiloader.py:214 - __init__()]	 Configuring multiloader with freqs [20, 3, 3] batches
[10.11 10:27:56] [util_multiloader.py:257 - _setup()]	 Finished setting up multiloader
	 batch_sizes: [256, 256, 256]
	 freq: [20, 3, 3]
[10.11 10:27:58] [train_abc.py:439 - verify_and_log_trainer_info()]	 Verifying that all metrics are OK. The outputs here are NOT from the model that was passed ifone was passed
[10.11 10:27:58] [train_abc.py:549 - val_step()]	 Evaluating at all_step 0 (epoch=0)...
[10.11 10:27:59] [train_abc.py:558 - val_step()]	 Primary eval; epoch: 0
[10.11 10:29:55] [train_abc.py:620 - validate_val_loader()]	 
 idx: -1
Source: Desk register taken no further than Ozzie? (7)
 	Target: rolltop
	 Actual: Ozzie? (7) (7) (8) (8) (8) (8) (8) 

[10.11 10:30:00] [train_abc.py:568 - val_step()]	 Multitask eval; epoch: 0
[10.11 10:30:00] [train_abc.py:570 - val_step()]	 Validating DL acw
[10.11 10:30:36] [train_abc.py:570 - val_step()]	 Validating DL acw_descramble
[10.11 10:30:57] [train_abc.py:447 - verify_and_log_trainer_info()]	 Tracking metrics [('dev/num_match_top_sampled', True), ('multisave', True), ('multi/acw/num_match_in_sample', True), ('epoch', True)] all verified
[10.11 10:30:57] [train_abc.py:477 - verify_and_log_trainer_info()]	 
total_train_steps (num_train_ex * epochs): 711900
machine: ws-l6-020
num_train: 85428
num_val: 28476ada: True
ada_constant: False
add_special_tokens: False
batch_size: 256
batched_dl: True
ckpt_path: None
comment: 
data_dir: ../data/clue_json/guardian/naive_random
default_train: base
default_val: None
dev_run: False
do_sample: True
do_save: True
early_stopping: None
fast_tokenizer: True
generation_beams: 5
grad_accum_steps: 1
hacky: False
model_name: t5-base
multi_gpu: None
multitask: final_top_result_scaled_up
multitask_num: -1
name: naive_random_Cirrucular
no_train: False
num_epochs: 25
num_train: 85428
num_val: 28476
num_workers: 4
project: baseline
resume_train: None
seed: 42
special: None
test: False
total_train: 711900
use_json: True
val_freq: None
wandb_dir: ../../wandb
multitask:
{
  "multitask_config": {
    "freq_list": [
      20,
      3,
      3
    ],
    "multitask_dir": "../data/clue_json/curricular",
    "num_warmup": 4,
    "reset": true,
    "tasks": [
      {
        "collate_fn": "coll_fn",
        "dir": "ACW_data",
        "name": "acw",
        "val_fcn_list": [
          "compute_metrics_sampled_primary"
        ]
      },
      {
        "collate_fn": "coll_fn",
        "dir": "ACW_data",
        "name": "acw_descramble",
        "val_fcn_list": [
          "compute_metrics_sampled_primary"
        ]
      }
    ],
    "val_split_pct": 0.99
  }
}

[10.11 10:30:59] [train_abc.py:343 - run()]	 For actual train, epochs start at 11
[10.11 10:30:59] [train_abc.py:948 - train_step()]	 Training warmup=1...
 ending 
