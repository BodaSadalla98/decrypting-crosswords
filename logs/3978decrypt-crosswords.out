starting.......................
[10.11 11:46:27] [train_clues.py:132 - <module>()]	 train_clues.py --default_train=base --name=naive_random_Cirrucular --project=baseline --wandb_dir=../../wandb --data_dir=../data/clue_json/guardian/naive_random --num_epochs=15 --multitask=ACW --batch_size=128
[10.11 11:46:27] [util.py:168 - set_seed()]	 Setting seed
[10.11 11:46:27] [util_checkpoint.py:65 - __init__()]	 Saver will track (metric, maximize?)
 [('dev/num_match_top_sampled', True), ('multisave', True), ('multi/acw/num_match_in_sample', True), ('epoch', True)]
[10.11 11:46:27] [util.py:86 - get_available_devices()]	 Device: cuda:0	 GPU IDs: [0]	 machine: ws-l6-014

[10.11 11:49:24] [train_abc.py:782 - setup_dataloaders_multi()]	 Setting up for multitask
[10.11 11:49:25] [util_dataloader_batch.py:56 - __init__()]	 Loading cluedatasetbatched of type train
[10.11 11:49:25] [util_dataloader_batch.py:72 - __init__()]	 For dataset, found readme: 
[10.11 11:49:25] [util_dataloader_batch.py:73 - __init__()]	 ['Guardian data. Split: naive_random\n', 'Total: 142380\n', 'splits: [85428, 28476, 28476]\n', '\n', "{'idx': -1,\n", " 'input': 'Suffering to grasp edge of plant (8)',\n", " 'target': 'agrimony'}\n", "{'idx': -1,\n", " 'input': 'Honour Ben and Noel with new order (7)',\n", " 'target': 'ennoble'}\n", "{'idx': -1, 'input': 'Bit the royal we love? Cheers! (4)', 'target': 'iota'}\n", '\n', '\n']
[10.11 11:49:28] [util_dataloader_batch.py:197 - _get_dataloader_batched()]	 Dataset train loaded with size: 85428
[10.11 11:49:37] [util_dataloader_batch.py:34 - __post_init_check()]	 Dataloader:
	Try to convert Senegal? I've failed (10) => evangelise
[10.11 11:49:37] [util_dataloader_batch.py:174 - _get_dataloader_from_dataset()]	 Dataloader loaded from dataset
[10.11 11:49:37] [util_dataloader_batch.py:56 - __init__()]	 Loading cluedatasetbatched of type val
[10.11 11:49:45] [util_dataloader_batch.py:197 - _get_dataloader_batched()]	 Dataset val loaded with size: 28476
[10.11 11:49:46] [util_dataloader_batch.py:34 - __post_init_check()]	 Dataloader:
	Desk register taken no further than Ozzie? (7) => rolltop
[10.11 11:49:46] [util_dataloader_batch.py:174 - _get_dataloader_from_dataset()]	 Dataloader loaded from dataset
[10.11 11:49:46] [util_multiloader.py:110 - _prepare_dataloaders()]	 For task acw, using cfg-provided collate function
[10.11 11:49:46] [util_dataloader_batch.py:56 - __init__()]	 Loading cluedatasetbatched of type train
[10.11 11:49:46] [util_dataloader_batch.py:72 - __init__()]	 For dataset, found readme: 
[10.11 11:49:46] [util_dataloader_batch.py:73 - __init__()]	 ['ACW set; xd cw set, all\n', 'Total: 2234863\n', 'splits: [2234863]\n', '\n', '{\'idx\': 0, \'input\': "Litigator\'s group (3)", \'target\': \'aba\'}\n', "{'idx': 1, 'input': 'Arab garment (3)', 'target': 'aba'}\n", "{'idx': 2, 'input': 'Arabian garment (3)', 'target': 'aba'}\n", '\n', '\n']
[10.11 11:50:45] [util_dataloader_batch.py:34 - __post_init_check()]	 Dataloader:
	phrase: Getting through a busy toll plaza, e.g (6) => hassle
[10.11 11:50:47] [util_dataloader_batch.py:174 - _get_dataloader_from_dataset()]	 Dataloader loaded from dataset
[10.11 11:50:53] [util_dataloader_batch.py:34 - __post_init_check()]	 Dataloader:
	phrase: Darks or whites (4) => load
[10.11 11:50:54] [util_dataloader_batch.py:174 - _get_dataloader_from_dataset()]	 Dataloader loaded from dataset
[10.11 11:50:55] [util_multiloader.py:214 - __init__()]	 Configuring multiloader with freqs [20, 6] batches
[10.11 11:51:04] [util_multiloader.py:257 - _setup()]	 Finished setting up multiloader
	 batch_sizes: [128, 128]
	 freq: [20, 6]
[10.11 11:51:07] [train_abc.py:439 - verify_and_log_trainer_info()]	 Verifying that all metrics are OK. The outputs here are NOT from the model that was passed ifone was passed
[10.11 11:51:07] [train_abc.py:549 - val_step()]	 Evaluating at all_step 0 (epoch=0)...
[10.11 11:51:07] [train_abc.py:558 - val_step()]	 Primary eval; epoch: 0
[10.11 11:53:01] [train_abc.py:620 - validate_val_loader()]	 
 idx: -1
Source: Desk register taken no further than Ozzie? (7)
 	Target: rolltop
	 Actual: Ozzie? (7) (7) (8) (8) (8) (8) (8) 

[10.11 11:53:05] [train_abc.py:568 - val_step()]	 Multitask eval; epoch: 0
[10.11 11:53:05] [train_abc.py:570 - val_step()]	 Validating DL acw
[10.11 11:53:34] [train_abc.py:447 - verify_and_log_trainer_info()]	 Tracking metrics [('dev/num_match_top_sampled', True), ('multisave', True), ('multi/acw/num_match_in_sample', True), ('epoch', True)] all verified
[10.11 11:53:34] [train_abc.py:477 - verify_and_log_trainer_info()]	 
total_train_steps (num_train_ex * epochs): 427140
machine: ws-l6-014
num_train: 85428
num_val: 28476ada: True
ada_constant: False
add_special_tokens: False
batch_size: 128
batched_dl: True
ckpt_path: None
comment: 
data_dir: ../data/clue_json/guardian/naive_random
default_train: base
default_val: None
dev_run: False
do_sample: True
do_save: True
early_stopping: None
fast_tokenizer: True
generation_beams: 5
grad_accum_steps: 1
hacky: False
model_name: t5-base
multi_gpu: None
multitask: ACW
multitask_num: -1
name: naive_random_Cirrucular
no_train: False
num_epochs: 15
num_train: 85428
num_val: 28476
num_workers: 4
project: baseline
resume_train: None
seed: 42
special: None
test: False
total_train: 427140
use_json: True
val_freq: None
wandb_dir: ../../wandb
multitask:
{
  "multitask_config": {
    "freq_list": [
      20,
      6
    ],
    "multitask_dir": "../data/clue_json/curricular",
    "num_warmup": 4,
    "reset": true,
    "tasks": [
      {
        "collate_fn": "coll_fn",
        "dir": "ACW_data",
        "name": "acw",
        "val_fcn_list": [
          "compute_metrics_sampled_primary"
        ]
      }
    ],
    "val_split_pct": 0.99
  }
}

[10.11 11:53:35] [train_abc.py:343 - run()]	 For actual train, epochs start at 11
[10.11 11:53:35] [train_abc.py:948 - train_step()]	 Training warmup=1...
[10.11 12:11:32] [utils.py:148 - _init_num_threads()]	 Note: NumExpr detected 32 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[10.11 12:11:33] [utils.py:160 - _init_num_threads()]	 NumExpr defaulting to 8 threads.
[10.11 23:42:51] [train_abc.py:549 - val_step()]	 Evaluating at all_step 2212514 (epoch=1)...
[10.11 23:42:52] [train_abc.py:568 - val_step()]	 Multitask eval; epoch: 1
[10.11 23:42:52] [train_abc.py:570 - val_step()]	 Validating DL acw
[10.11 23:46:52] [train_abc.py:493 - val_end_epoch()]	 multi/acw/num_match_in_sample: 7296.00	 avg: 0.2562
[10.11 23:46:52] [train_abc.py:493 - val_end_epoch()]	 multi/acw/num_match_top_sampled: 4297.00	 avg: 0.1509
[10.11 23:46:52] [train_abc.py:493 - val_end_epoch()]	 multi/acw/NLL: 01.85	 avg: 1.8513
[10.11 23:46:52] [util_checkpoint.py:142 - save_if_best()]	 Best metric for multisave = 1 at epoch=1
[10.11 23:46:52] [util_checkpoint.py:113 - save_most_recent()]	 Saving most recent model at epoch=1 to ../../wandb/wandb/run-20231011_114626-xef8hbvo/files/epoch_1.pth.tar
[10.11 23:47:40] [util_checkpoint.py:142 - save_if_best()]	 Best metric for multi/acw/num_match_in_sample = 7296 at epoch=1
[10.11 23:47:40] [util_checkpoint.py:142 - save_if_best()]	 Best metric for epoch = 1 at epoch=1
[10.11 23:47:40] [train_abc.py:948 - train_step()]	 Training warmup=2...
